{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4a3afa8",
   "metadata": {},
   "source": [
    "# # Save Data\n",
    "# Export scraped job data to various formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2796e8",
   "metadata": {},
   "source": [
    "## Load Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e065e6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Configuration loaded successfully\n",
      "  - Default threads: 3\n",
      "  - Max threads: 15\n",
      "  - WebDriver timeout: 10s\n"
     ]
    }
   ],
   "source": [
    "%run config.ipynb\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef506fc",
   "metadata": {},
   "source": [
    "## Check if Records Exist\n",
    "# Make sure you've run main_scraper.ipynb first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd59c237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 16 records from Jupyter storage\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    %store -r records\n",
    "    print(f\"✓ Loaded {len(records)} records from Jupyter storage\")\n",
    "except:\n",
    "    print(\"⚠ No stored records found\")\n",
    "    print(\"Attempting to check current memory...\")\n",
    "    \n",
    "    # Option 2: Check if records exists in current memory\n",
    "    try:\n",
    "        test = records\n",
    "        print(f\"✓ Found {len(records)} records in current session\")\n",
    "    except NameError:\n",
    "        print(\"\\n❌ ERROR: No 'records' variable found!\")\n",
    "        print(\"\\nPlease do ONE of the following:\")\n",
    "        print(\"  1. Run 4_main_scraper.ipynb in this same Jupyter session\")\n",
    "        print(\"  2. Or add '%store records' at the end of 4_main_scraper.ipynb\")\n",
    "        print(\"     Then run: %store -r records\")\n",
    "        print(\"  3. Or run: %run 4_main_scraper.ipynb\")\n",
    "        \n",
    "        records = []  # Empty list to prevent errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1453bf99",
   "metadata": {},
   "source": [
    "## Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62af4fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(records, filename=\"indeed_jobs.csv\"):\n",
    "    \"\"\"\n",
    "    Save job records to CSV file\n",
    "    \n",
    "    Args:\n",
    "        records: List of job tuples\n",
    "        filename: Output CSV filename\n",
    "    \"\"\"\n",
    "    if not records:\n",
    "        print(\"⚠ No records to save\")\n",
    "        return\n",
    "    \n",
    "    headers = [\"Title\", \"Company\", \"Location\", \"Salary\", \"URL\", \"Description\"]\n",
    "    \n",
    "    with open(filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(headers)\n",
    "        writer.writerows(records)\n",
    "    \n",
    "    print(f\"✓ Data saved to {filename}\")\n",
    "    print(f\"  Rows: {len(records)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b53fb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data saved to indeed_jobs_20251003_201222.csv\n",
      "  Rows: 16\n"
     ]
    }
   ],
   "source": [
    "# Execute CSV save\n",
    "csv_filename = f\"indeed_jobs_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "save_to_csv(records, csv_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9250b364",
   "metadata": {},
   "source": [
    "## Save to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b420d813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_excel(records, filename=\"indeed_jobs.xlsx\"):\n",
    "    \"\"\"\n",
    "    Save job records to Excel file with formatting\n",
    "    \n",
    "    Args:\n",
    "        records: List of job tuples\n",
    "        filename: Output Excel filename\n",
    "    \"\"\"\n",
    "    if not records:\n",
    "        print(\"⚠ No records to save\")\n",
    "        return\n",
    "    \n",
    "    df = pd.DataFrame(records, columns=[\"Title\", \"Company\", \"Location\", \"Salary\", \"URL\", \"Description\"])\n",
    "    # Save with auto-column width\n",
    "    with pd.ExcelWriter(filename, engine='openpyxl') as writer:\n",
    "        df.to_excel(writer, index=False, sheet_name='Jobs')\n",
    "        \n",
    "        # Auto-adjust column widths\n",
    "        worksheet = writer.sheets['Jobs']\n",
    "        for idx, col in enumerate(df.columns):\n",
    "            max_length = max(\n",
    "                df[col].astype(str).apply(len).max(),\n",
    "                len(col)\n",
    "            )\n",
    "            worksheet.column_dimensions[chr(65 + idx)].width = min(max_length + 2, 50)\n",
    "    \n",
    "    print(f\"✓ Data saved to {filename}\")\n",
    "    print(f\"  Rows: {len(records)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba55552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data saved to indeed_jobs_20251003_201256.xlsx\n",
      "  Rows: 16\n"
     ]
    }
   ],
   "source": [
    "# Execute Excel save\n",
    "excel_filename = f\"indeed_jobs_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
    "save_to_excel(records, excel_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb5e0f5",
   "metadata": {},
   "source": [
    "## Save to JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95a4f6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_json(records, filename=\"indeed_jobs.json\"):\n",
    "    \"\"\"\n",
    "    Save job records to JSON file\n",
    "    \n",
    "    Args:\n",
    "        records: List of job tuples\n",
    "        filename: Output JSON filename\n",
    "    \"\"\"\n",
    "    if not records:\n",
    "        print(\"⚠ No records to save\")\n",
    "        return\n",
    "    \n",
    "    jobs_list = []\n",
    "    for record in records:\n",
    "        job_dict = {\n",
    "            \"title\": record[0],\n",
    "            \"company\": record[1],\n",
    "            \"location\": record[2],\n",
    "            \"salary\": record[3],\n",
    "            \"url\": record[4],\n",
    "            \"description\": record[5]\n",
    "        }\n",
    "        jobs_list.append(job_dict)\n",
    "    \n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(jobs_list, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"✓ Data saved to {filename}\")\n",
    "    print(f\"  Records: {len(jobs_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b47b32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data saved to indeed_jobs_20251003_201403.json\n",
      "  Records: 16\n"
     ]
    }
   ],
   "source": [
    "# Execute JSON save\n",
    "json_filename = f\"indeed_jobs_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "save_to_json(records, json_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3974915e",
   "metadata": {},
   "source": [
    "## Data Quality Report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81240af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DATA QUALITY REPORT\n",
      "================================================================================\n",
      "\n",
      "Total records: 16\n",
      "\n",
      "Missing salaries: 16 (100.0%)\n",
      "Missing descriptions: 1 (6.2%)\n",
      "\n",
      "Top 5 companies:\n",
      "Company\n",
      "General Motors                                        8\n",
      "Disney Entertainment and ESPN Product & Technology    2\n",
      "Advantest                                             1\n",
      "Infosys                                               1\n",
      "CuraFi                                                1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top 5 locations:\n",
      "Location\n",
      "Mountain View, CA                                      6\n",
      "San Francisco, CA 94105 \\n(Financial District area)    2\n",
      "Remote in Mountain View, CA                            1\n",
      "San Jose, CA 95134 \\n(North San Jose area)             1\n",
      "Cupertino, CA                                          1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "if records:\n",
    "    df = pd.DataFrame(records, columns=[\"Title\", \"Company\", \"Location\", \"Salary\", \"URL\", \"Description\"])\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DATA QUALITY REPORT\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nTotal records: {len(df)}\")\n",
    "    print(f\"\\nMissing salaries: {df['Salary'].eq('').sum()} ({df['Salary'].eq('').sum()/len(df)*100:.1f}%)\")\n",
    "    print(f\"Missing descriptions: {df['Description'].eq('None').sum()} ({df['Description'].eq('None').sum()/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nTop 5 companies:\")\n",
    "    print(df['Company'].value_counts().head())\n",
    "    \n",
    "    print(f\"\\nTop 5 locations:\")\n",
    "    print(df['Location'].value_counts().head())\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c07ca33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ All data export operations complete!\n",
      "\n",
      "Files created:\n",
      "  - indeed_jobs_20251003_201222.csv\n",
      "  - indeed_jobs_20251003_201256.xlsx\n",
      "  - indeed_jobs_20251003_201403.json\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n✓ All data export operations complete!\")\n",
    "print(f\"\\nFiles created:\")\n",
    "print(f\"  - {csv_filename}\")\n",
    "print(f\"  - {excel_filename}\")\n",
    "print(f\"  - {json_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
